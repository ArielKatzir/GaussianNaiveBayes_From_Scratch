{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabSheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up dataframes\n",
    "fruit_dataset = pd.read_table(\"fruit_data_with_colors.txt\")\n",
    "X = fruit_dataset[['mass','width','height','color_score']]\n",
    "Y = fruit_dataset['fruit_name']\n",
    "\n",
    "# list of features\n",
    "heads = list(X.columns.values)\n",
    "\n",
    "# random state is set to keep the results constant when testing the code\n",
    "# used 0.3 for test size because thats what the question asked(70/30)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.3 , random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 7)\n",
      "(59, 4)\n",
      "(59,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ariel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\ariel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\ariel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# datasizes\n",
    "print(fruit_dataset.shape)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# preprocessing\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best k using accuracy score and confusion matrix (knn)\n",
    "scores_knn = []\n",
    "confusion_matrices_knn = []\n",
    "\n",
    "for k in range(1,9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train,Y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(Y_test,pred)\n",
    "    matrix = confusion_matrix(Y_test,pred)\n",
    "    scores_knn.append(accuracy)\n",
    "    confusion_matrices_knn.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding accuracy score and confusion matrix (Guassian)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,Y_train)\n",
    "pred = gnb.predict(X_test)\n",
    "accuracy_gnb = metrics.accuracy_score(Y_test,pred)\n",
    "confusion_matrix_gnb = confusion_matrix(Y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With knn, for k=1 accuracy score is 94.4% and the confusion matrix is \n",
      "[[6 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 2 0]\n",
      " [1 0 0 3]]\n",
      "\n",
      "With knn, for k=2 accuracy score is 94.4% and the confusion matrix is \n",
      "[[6 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 2 0]\n",
      " [1 0 0 3]]\n",
      "\n",
      "With knn, for k=3 accuracy score is 100.0% and the confusion matrix is \n",
      "[[6 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 4]]\n",
      "\n",
      "With knn, for k=4 accuracy score is 100.0% and the confusion matrix is \n",
      "[[6 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 4]]\n",
      "\n",
      "With knn, for k=5 accuracy score is 100.0% and the confusion matrix is \n",
      "[[6 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 4]]\n",
      "\n",
      "With knn, for k=6 accuracy score is 100.0% and the confusion matrix is \n",
      "[[6 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 4]]\n",
      "\n",
      "With knn, for k=7 accuracy score is 100.0% and the confusion matrix is \n",
      "[[6 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 4]]\n",
      "\n",
      "With knn, for k=8 accuracy score is 88.9% and the confusion matrix is \n",
      "[[6 0 0 0]\n",
      " [0 6 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 4]]\n",
      "\n",
      "The accuracy when using the Gaussian Naïve Bayes classifier is: 83.3%. And the confusion matrix is: \n",
      "[[6 0 0 0]\n",
      " [0 5 0 1]\n",
      " [0 0 2 0]\n",
      " [2 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scores_knn)):\n",
    "    print(\"With knn, for k=\" + str(i+1) + \" accuracy score is \" + str(round(1000*scores_knn[i])/10) + \"% and the confusion matrix is \" + \"\\n\" + str(confusion_matrices_knn[i]) + \"\\n\")\n",
    "    \n",
    "print(\"The accuracy when using the Gaussian Naïve Bayes classifier is: \" + str(round(1000*accuracy_gnb)/10) + \"%. And the confusion matrix is: \" + \"\\n\" + str(confusion_matrix_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We’re only looking for argmaxc(P(d|c) * P(c))\n",
    "##### P(c) is the prior probability and is calculated by dividing the number of times a class member appears in our training data by the total size of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return probability of a class member being in the dataset. Parameter - fruit label (int from 1 - 4)\n",
    "def P_c (label):\n",
    "    label+=1\n",
    "    counter = 0\n",
    "    for entry in fruit_dataset['fruit_label']:\n",
    "        if entry == label:\n",
    "            counter+=1\n",
    "    return counter/ fruit_dataset.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    fruit_label fruit_name     fruit_subtype  mass  width  height  color_score\n",
      "0             1      apple      granny_smith   192    8.4     7.3         0.55\n",
      "1             1      apple      granny_smith   180    8.0     6.8         0.59\n",
      "2             1      apple      granny_smith   176    7.4     7.2         0.60\n",
      "8             1      apple          braeburn   178    7.1     7.8         0.92\n",
      "9             1      apple          braeburn   172    7.4     7.0         0.89\n",
      "10            1      apple          braeburn   166    6.9     7.3         0.93\n",
      "11            1      apple          braeburn   172    7.1     7.6         0.92\n",
      "12            1      apple          braeburn   154    7.0     7.1         0.88\n",
      "13            1      apple  golden_delicious   164    7.3     7.7         0.70\n",
      "14            1      apple  golden_delicious   152    7.6     7.3         0.69\n",
      "15            1      apple  golden_delicious   156    7.7     7.1         0.69\n",
      "16            1      apple  golden_delicious   156    7.6     7.5         0.67\n",
      "17            1      apple  golden_delicious   168    7.5     7.6         0.73\n",
      "18            1      apple       cripps_pink   162    7.5     7.1         0.83\n",
      "19            1      apple       cripps_pink   162    7.4     7.2         0.85\n",
      "20            1      apple       cripps_pink   160    7.5     7.5         0.86\n",
      "21            1      apple       cripps_pink   156    7.4     7.4         0.84\n",
      "22            1      apple       cripps_pink   140    7.3     7.1         0.87\n",
      "23            1      apple       cripps_pink   170    7.6     7.9         0.88,    fruit_label fruit_name fruit_subtype  mass  width  height  color_score\n",
      "3            2   mandarin      mandarin    86    6.2     4.7         0.80\n",
      "4            2   mandarin      mandarin    84    6.0     4.6         0.79\n",
      "5            2   mandarin      mandarin    80    5.8     4.3         0.77\n",
      "6            2   mandarin      mandarin    80    5.9     4.3         0.81\n",
      "7            2   mandarin      mandarin    76    5.8     4.0         0.81,     fruit_label fruit_name     fruit_subtype  mass  width  height  color_score\n",
      "24            3     orange     spanish_jumbo   342    9.0     9.4         0.75\n",
      "25            3     orange     spanish_jumbo   356    9.2     9.2         0.75\n",
      "26            3     orange     spanish_jumbo   362    9.6     9.2         0.74\n",
      "27            3     orange  selected_seconds   204    7.5     9.2         0.77\n",
      "28            3     orange  selected_seconds   140    6.7     7.1         0.72\n",
      "29            3     orange  selected_seconds   160    7.0     7.4         0.81\n",
      "30            3     orange  selected_seconds   158    7.1     7.5         0.79\n",
      "31            3     orange  selected_seconds   210    7.8     8.0         0.82\n",
      "32            3     orange  selected_seconds   164    7.2     7.0         0.80\n",
      "33            3     orange      turkey_navel   190    7.5     8.1         0.74\n",
      "34            3     orange      turkey_navel   142    7.6     7.8         0.75\n",
      "35            3     orange      turkey_navel   150    7.1     7.9         0.75\n",
      "36            3     orange      turkey_navel   160    7.1     7.6         0.76\n",
      "37            3     orange      turkey_navel   154    7.3     7.3         0.79\n",
      "38            3     orange      turkey_navel   158    7.2     7.8         0.77\n",
      "39            3     orange      turkey_navel   144    6.8     7.4         0.75\n",
      "40            3     orange      turkey_navel   154    7.1     7.5         0.78\n",
      "41            3     orange      turkey_navel   180    7.6     8.2         0.79\n",
      "42            3     orange      turkey_navel   154    7.2     7.2         0.82,     fruit_label fruit_name   fruit_subtype  mass  width  height  color_score\n",
      "43            4      lemon  spanish_belsan   194    7.2    10.3         0.70\n",
      "44            4      lemon  spanish_belsan   200    7.3    10.5         0.72\n",
      "45            4      lemon  spanish_belsan   186    7.2     9.2         0.72\n",
      "46            4      lemon  spanish_belsan   216    7.3    10.2         0.71\n",
      "47            4      lemon  spanish_belsan   196    7.3     9.7         0.72\n",
      "48            4      lemon  spanish_belsan   174    7.3    10.1         0.72\n",
      "49            4      lemon         unknown   132    5.8     8.7         0.73\n",
      "50            4      lemon         unknown   130    6.0     8.2         0.71\n",
      "51            4      lemon         unknown   116    6.0     7.5         0.72\n",
      "52            4      lemon         unknown   118    5.9     8.0         0.72\n",
      "53            4      lemon         unknown   120    6.0     8.4         0.74\n",
      "54            4      lemon         unknown   116    6.1     8.5         0.71\n",
      "55            4      lemon         unknown   116    6.3     7.7         0.72\n",
      "56            4      lemon         unknown   116    5.9     8.1         0.73\n",
      "57            4      lemon         unknown   152    6.5     8.5         0.72\n",
      "58            4      lemon         unknown   118    6.1     8.1         0.70]\n"
     ]
    }
   ],
   "source": [
    "#  spliiting the train data to their classes\n",
    "classes = []\n",
    "# find number of classes\n",
    "no_classes = max(fruit_dataset['fruit_label'])\n",
    "\n",
    "# creating df for each class for later use\n",
    "for i in range(no_classes):\n",
    "    Class = fruit_dataset.loc[fruit_dataset['fruit_label'] == i+1]\n",
    "    classes.append(Class)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  d consists of the values (x1, x2, x3,…) and we assume the elements are independent then: P(d|c) = P(x1|c)P(x2|c)P(x3|c)…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First - find varience and mean of each feature in each class\n",
    "\n",
    "def mean(feature, class_id):\n",
    "    mean = sum(classes[class_id][feature]) / classes[class_id].shape[0]  \n",
    "    return mean\n",
    "\n",
    "def varience(feature ,class_id):\n",
    "    varience = sum((i - mean(feature, class_id)) ** 2 for i in classes[class_id][feature]) / len(classes[class_id][feature]) \n",
    "    return varience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To find P(d|c) apply Guassian distribution with the pdf\n",
    "def gaussian(x, mean, varience):\n",
    "    return (1/math.sqrt(2*math.pi*varience) * math.exp(-0.5 * math.pow((x - mean),2)/varience))\n",
    "\n",
    "# Change the function for ease of use\n",
    "def gaus(x , feature , class_id):\n",
    "    return gaussian(x , mean(feature , class_id) ,varience (feature, class_id))\n",
    "#     print(\"gaus: \" + str(gaussian(x , mean(feature , class_id) ,varience (feature, class_id))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier\n",
    "\n",
    "def Gaussian_classifier_fruits(test_vectors):\n",
    "    test_vectors = test_vectors[['mass','width','height','color_score']]\n",
    "    predictions = []\n",
    "    for row in range(test_vectors.shape[0]):\n",
    "        results = []\n",
    "        for class_id in range(len(classes)):\n",
    "            prob = 1\n",
    "            for head in heads:\n",
    "                prob = prob * gaus (X_test[head][row] ,head, class_id)\n",
    "            results.append(prob * P_c(class_id))\n",
    "        predictions.append(results.index(max(results)) + 1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine: [1, 1, 2, 2, 1, 1, 4, 4, 3, 3, 1, 1, 1, 1]\n",
      "sklearn: [1 1 3 2 1 1 4 4 3 1 1 1 1 1]\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# I chose to have the classifier work on the same format as the original dataset (to make it more practical), so instead\n",
    "# of using train_test_split I chose random entries from the whole dataset,\n",
    "# made a train file and ran them on the classifier function\n",
    "\n",
    "fruit_dataset_train = pd.read_table(\"train.txt\")\n",
    "fruit_dataset_test = pd.read_table(\"test.txt\")\n",
    "\n",
    "X_train = fruit_dataset_train[['mass','width','height','color_score']]\n",
    "X_test = fruit_dataset_test[['mass','width','height','color_score']]\n",
    "Y_train = fruit_dataset_train['fruit_label']\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,Y_train)\n",
    "pred = gnb.predict(X_test)\n",
    "\n",
    "print(\"mine: \" + str(Gaussian_classifier_fruits(X_test)))\n",
    "print(\"sklearn: \" + str(pred))\n",
    "accuracy = metrics.accuracy_score(pred,Gaussian_classifier_fruits(X_test))\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
